Your ClimMob report
You are reading a report generated by ClimMob. This is a software package to analyze data generated by citizen science or crowdsourcing.
Author
Introduction
In agriculture, the local environmental conditions determine to a large degree which technological solutions are the most suitable. In dry soils, for example, drought-resistant crop varieties will outperform other varieties, but in wet soils these same varieties may do worse than most. Not only drought, but an entire range of problems including excessive heat, floods, new pests and diseases tend to intensify under climate change. This multitude of limiting factors requires multiple technological solutions, tested in diverse environments. 
Citizen science is based on the cooperation of citizen scientist or observers (paid or unpaid). Researchers assign microtasks (observations, experiments...) that, once completed and gathered, contribute with a great amount of information to science. One of the advantages of citizen science is that agricultural researchers can get access to many environments by crowdsourcing their experiments. As farmers contribute with their time, skills and knowledge to the investigation, researchers are able to do more tests than in a traditional setup. Also citizen scientists acquire new knowledge, abilities and information useful for future challenges of their work.
ClimMob
The primary goal of ClimMob is to help farmers adapt to variable and changing climates. ClimMob was created as part of Bioversity International's research in the CGIAR Research Programme on Climate Change, Agriculture, and Food Security (CCAFS). It serves to prepare and analyze citizen science experiments in which a large number of farmers observe and compare different technological options under a wide range environmental conditions (van Etten 2011). 
ClimMob software assigns a limited number of items (typically 3 crop varieties or agricultural practices) to each farmer, who will compare their performance. Each farmer gets a different combination of items drawn from a much larger set of items. Comparisons of this kind are thought to be a very reliable way to obtain data from human observers (Martin 2004). Once the results of the microtasks have been collected, ClimMob builds an image of the whole set of assigned objects, combining all observations. ClimMob not only reconstructs the overall ordering of items, but also takes into account differences and similarities between observers and the conditions under which they observe. It assigns similar observers to groups that each corresponds to a different preference profile. Groups are created on the basis of variables such as the characteristics of the plot, geography, age, gender...
ClimMob uses a recently published statistical method to analyze ranking data (Strobl et al. 2011). It automatically generates analytical reports, as well as individualized information sheets for each participant. ClimMob will hopefully help many agricultural researchers to start using crowdsourcing approaches in order to accelerate climate change adaptation.
Complementary to the microtaks performed by the farmers, a detailed environmental monitoring is performed, using new, cheap sensors (Mittra et al. 2013), makes it possible to compare across sites and predict crop variety performance for new places.
How to cite
If you publish any results generated with ClimMob, you should cite a number of articles as the package builds on various contributions. Van Etten (2011) introduced the crowdsourcing philosophy behind ClimMob. It is important to mention that ClimMob is implemented in R, a free, open-source analysis software (R Development Core Team 2012). Methodologically, if you report on the tree results, you should mentioned that ClimMob applies the Bradley-Terry tree method published by Strobl et al. (2011). To cite ClimMob itself, mention Van Etten & Calderer (2015).
Interpretation
Here are some hints to help you interpret the results that follow.
The first three tables that follow give a summary of the variables, the items that entered the analysis and the characteristics evaluated in the project report.
Subsequently there is a Bradley-Terry tree figure for each combination of the explanatory variables chosen. The figure gives a visual representation of how the groups were formed and their preference profiles.
At the Bradley-Terry Tree figure, the values at the bottom rectangles (called terminal nodes) are the "worth" of the items. Worth rescales the scores to sum to one, for each group (node) that has been identified. It represents the degree of success of each item in the group. Each node represents a group of observers, and has a corresponding "relative estimation" figure and table next to the Bradley-Terry tree. 
The "relative estimation" figure gives an idea of the best and worst item in the corresponding node. The tables are meant for advanced users who want to perform extra calculations with the preliminary results shown. 
Data and results  
Number of observers	
Number of items (varieties) each observer ranks	
Number of characteristics for which each observer ranks
Number of types of items (varieties)
Variable
Value
Types of items (varieties)
Names
Characteristics of each item (variety) that were evaluated
Characteristics evaluated
CHARACTERISTIC:
Explanatory Variable(s):
Relative Performance at node 
Worth represents the relative score of each item (variety). They sum to one, for each group (node) that has been identified.
References
van Etten, J. and Calderer, L. 2015. ClimMob. Crowdsourcing climate-smart agriculture. R package.
van Etten, J. 2011. Crowdsourcing crop improvement in sub-Saharan Africa: A proposal for a scalable and inclusive approach to food security. IDS Bulletin 42(4), 102-110.
Martin, G.J. 2004. Ethnobotany. A Methods Manual. London: Earthscan.
Carolin Strobl, Florian Wickelmaier, Achim Zeileis (2011). Accounting for individual differences in Bradley-Terry models by means of recursive partitioning. Journal of Educational and Behavioral Statistics, 36(2), 135-153. doi:10.3102/1076998609359791
Mittra, S., J. van Etten, and T. Franco. 2013. iButtons manual.
Verzani, J. gWidgets2. R package on GitHub
R Development Core Team (2014). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. ISBN 3-900051-07-0, URL http://www.R-project.org/
Better
Worse
If you have any extra questions about how the Bradley-Terry trees and the estimations of the nodes are calculated, please consult the paper by Strobl et al.(2011).
Variety
Estimation
Standard Error
Quasi Standard Error
Quasi Variance
The following explanatory variables: 
. Have NO significance in the model used. They only have one result node with the following values:
Relative Performance at the only node 
